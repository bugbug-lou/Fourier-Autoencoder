{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCAE_cd4_multigraphs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNi6wuORoXcKM4cuBnF9fsJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bugbug-lou/Fourier-Autoencoder/blob/main/FCAE_cd4_multigraphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeHjWkJOuC7M"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import numpy as np\r\n",
        "import torchvision\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.autograd import Variable\r\n",
        "import math\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "device \r\n",
        "\r\n",
        "bs = 2000 #batch_size\r\n",
        "transform = transforms.Compose(\r\n",
        "    [transforms.ToTensor()])\r\n",
        "\r\n",
        "mnist_trainset = datasets.MNIST(root='F:/MNISTdata', train=True,\r\n",
        "                                        download=True, transform=transform)\r\n",
        "mnist_trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=bs,\r\n",
        "                                          shuffle=True, num_workers=2)\r\n",
        "mnist_testset = datasets.MNIST(root='F:/MNISTdata', train=False,\r\n",
        "                                       download=True, transform=transform)\r\n",
        "mnist_testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=bs,\r\n",
        "                                         shuffle=False, num_workers=2)\r\n",
        "\r\n",
        "def get_all(arr):\r\n",
        "    # get all possible arrays given by taking tha negation of some coordinates of arr\r\n",
        "    dim = arr.shape[0]\r\n",
        "    vec = []\r\n",
        "    for i in range(dim):\r\n",
        "        if i == 0:\r\n",
        "            if arr[i] != 0:\r\n",
        "                k = int(arr[0])\r\n",
        "                vec.append(np.array([k]))\r\n",
        "                vec.append(np.array([-k]))\r\n",
        "            else:\r\n",
        "                vec.append(np.array([0]))\r\n",
        "\r\n",
        "        else:\r\n",
        "            if int(arr[i]) != 0:\r\n",
        "                for j in range(len(vec)):\r\n",
        "                    v = vec[j]\r\n",
        "                    l = np.copy(v)\r\n",
        "                    k = int(arr[i])\r\n",
        "                    k = np.array([k])\r\n",
        "                    vec[j] = np.concatenate((v, k))\r\n",
        "                    l = np.concatenate((l, -k))\r\n",
        "                    vec.append(l)\r\n",
        "            else:\r\n",
        "                for i in range(len(vec)):\r\n",
        "                    v = vec[i]\r\n",
        "                    vec[i] = np.concatenate((v, np.array([0])))\r\n",
        "    return vec\r\n",
        "\r\n",
        "def get_all_axis(dim, thres):\r\n",
        "    ## dim: dimension of each output vector\r\n",
        "    ## thres:\r\n",
        "    ## function returns all vectors of dimension dim such that each\r\n",
        "    ## coordinate of the vector takes integer value and\r\n",
        "    vecs, vecs1 = [], []\r\n",
        "    ind = 0\r\n",
        "    for i in range(thres * dim):\r\n",
        "        if i == 0:\r\n",
        "            vecs.append(np.zeros(dim))\r\n",
        "        else:\r\n",
        "            k = len(vecs)\r\n",
        "            c = set([])\r\n",
        "            for h in range(ind, k):\r\n",
        "                l = vecs[h]\r\n",
        "                for j in range(dim):\r\n",
        "                    if l[j] < thres:\r\n",
        "                        f = np.copy(l)\r\n",
        "                        f[j] = f[j] + 1\r\n",
        "                        f = f.tostring()\r\n",
        "                        c.add(f)\r\n",
        "            ind = k\r\n",
        "            for element in c:\r\n",
        "                element = np.fromstring(element)\r\n",
        "                vecs.append(element)\r\n",
        "    for v in vecs:\r\n",
        "        vecs1 = vecs1 + get_all(v)\r\n",
        "    return vecs1\r\n",
        "\r\n",
        "def get_fc(x, y, k):\r\n",
        "    ## x: input, y: output, k:frequency matrix (data dim first), w: weight given by the frequency axes\r\n",
        "    bs,cd = x.shape\r\n",
        "    k = k.reshape([cd,-1]) #cd*num of frequencies\r\n",
        "    w = torch.sum(torch.square(k), dim = 0) #length num\r\n",
        "    v = - 2.0 * math.pi * torch.matmul(x, k) #bs*num of freq\r\n",
        "    #v = v.reshape([1,-1])\r\n",
        "    v1 = torch.cos(v)\r\n",
        "    v2 = torch.sin(v)\r\n",
        "    #v = torch.view_as_complex(v).reshape([-1,1])\r\n",
        "    y = y.reshape([1,-1])\r\n",
        "    coeffr = torch.matmul(y, v1) / bs  #i*num of freq\r\n",
        "    coeffi = torch.matmul(y, v2) / bs\r\n",
        "    coeff = torch.square(coeffr) + torch.square(coeffi)\r\n",
        "    w = w.reshape([-1,1]) #numof freq*1\r\n",
        "    coeff = torch.matmul(coeff, w)\r\n",
        "    return coeff\r\n",
        "\r\n",
        "\r\n",
        "class CN(nn.Module):\r\n",
        "    def __init__(self, input_dims, output_dim):\r\n",
        "        #Here input_dims should be a list of length 3: height, width, channels\r\n",
        "        super(CN, self).__init__()\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.conv1 = nn.Conv2d(input_dims[2], 16, 5, padding = 2)\r\n",
        "        self.pool = nn.MaxPool2d(2, 2)\r\n",
        "        self.conv2 = nn.Conv2d(16, 6, 5, padding = 2)\r\n",
        "        self.com_height = input_dims[0]//4\r\n",
        "        self.com_width = input_dims[1]//4\r\n",
        "        self.fc1 = nn.Linear(6*self.com_height*self.com_width, output_dim)\r\n",
        "\r\n",
        "    #Dataset should have size num*channels*width*height\r\n",
        "    def forward(self, x):\r\n",
        "        l = len(x)\r\n",
        "        x = self.pool(F.relu(self.conv1(x)))\r\n",
        "        x = self.pool(F.relu(self.conv2(x)))\r\n",
        "        x = x.view(l, 6*self.com_height*self.com_width)\r\n",
        "        x = self.fc1(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "class RN(nn.Module):\r\n",
        "    def __init__(self, input_dims, output_dim):\r\n",
        "        #Here input_dims should be a list of length 3: height, width, channels\r\n",
        "        super(RN, self).__init__()\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.conv1 = nn.ConvTranspose2d(6, 16, 5, stride = 2, padding = 2, output_padding = 1)\r\n",
        "        self.conv2 = nn.ConvTranspose2d(16, input_dims[2], 5, stride = 2, padding = 2, output_padding = 1)\r\n",
        "        self.com_height = input_dims[0]//4\r\n",
        "        self.com_width = input_dims[1]//4\r\n",
        "        self.fc1 = nn.Linear(output_dim, 6*self.com_height*self.com_width)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = x.reshape(len(x), 6, self.com_width, self.com_height)\r\n",
        "        x = F.relu(self.conv1(x))\r\n",
        "        x = F.sigmoid(self.conv2(x))\r\n",
        "        return x\r\n",
        "\r\n",
        "class FCAE(object):\r\n",
        "    def __init__(self, input_dims, compress_dim, beta, thres):\r\n",
        "        self.compress_net = CN(input_dims, compress_dim).to(device)\r\n",
        "        self.retrieve_net = RN(input_dims, compress_dim).to(device)\r\n",
        "        self.optimiser = optim.Adam(list(self.compress_net.parameters())+list(self.retrieve_net.parameters()))\r\n",
        "        self.criterion = nn.MSELoss()\r\n",
        "        self.compress_dim = compress_dim\r\n",
        "        self.beta = beta\r\n",
        "        self.thres = thres\r\n",
        "        self.axes = torch.FloatTensor(get_all_axis(compress_dim, thres)).transpose(1,0).to(device)\r\n",
        "\r\n",
        "\r\n",
        "    #Use this method to compress a dataset.\r\n",
        "    def compress(self, data):\r\n",
        "        #data = torch.FloatTensor(data).to(device)\r\n",
        "        return self.compress_net(data)\r\n",
        "\r\n",
        "    def retrieve(self, data):\r\n",
        "        #data = torch.FloatTensor(data).to(device)\r\n",
        "        return self.retrieve_net(data)\r\n",
        "\r\n",
        "    #Dataset is a collection of data.\r\n",
        "    def train(self, dataset, labels, iter):\r\n",
        "        for i in range(iter):\r\n",
        "            loss = self.loss(dataset, labels)\r\n",
        "            self.optimiser.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            self.optimiser.step()\r\n",
        "\r\n",
        "    #Dataset should have dimension num*channel*height*width\r\n",
        "    def loss(self, dataset, labels):\r\n",
        "        #dataset = torch.FloatTensor(dataset).to(device)\r\n",
        "        compressed = self.compress(dataset) #of shape [batch_size, compress_dim]\r\n",
        "        FP_loss = self.FP(compressed, labels)\r\n",
        "        retrieved = self.retrieve(compressed)\r\n",
        "        loss = self.criterion(dataset, retrieved)\r\n",
        "        loss = loss + self.beta * FP_loss\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def FP(self, compressed, labels):\r\n",
        "        ## thres: the axis entry maximum value\r\n",
        "        ## k: specifying the function\r\n",
        "        ## get_all: function to be completed\r\n",
        "        FP_loss = get_fc(compressed,labels,self.axes)\r\n",
        "        return torch.sqrt(FP_loss)\r\n",
        "\r\n",
        "\r\n",
        "    def MSE(self, dataset):\r\n",
        "        with torch.no_grad():\r\n",
        "            #dataset = torch.FloatTensor(dataset).to(device)\r\n",
        "            compressed = self.compress(dataset)\r\n",
        "            retrieved = self.retrieve(compressed)\r\n",
        "            loss = self.criterion(dataset, retrieved)\r\n",
        "        return loss\r\n",
        "\r\n",
        "def train(model, epoches_num):\r\n",
        "    for epoch in range(epoches_num):  # loop over the dataset multiple times \r\n",
        "\r\n",
        "        running_loss = 0.0\r\n",
        "        running_fp = 0.0\r\n",
        "        for i, data in enumerate(mnist_trainloader, 0):\r\n",
        "            # get the inputs\r\n",
        "            inputs, labels = data\r\n",
        "            # print inputs.numpy().shape\r\n",
        "\r\n",
        "            # wrap them in Variable\r\n",
        "            #inputs, labels = Variable(inputs), Variable(labels)\r\n",
        "            inputs= Variable(inputs).to(device)\r\n",
        "            with torch.no_grad():\r\n",
        "                labels = torch.FloatTensor(np.asarray(labels))/10\r\n",
        "            labels  = Variable(labels).to(device)\r\n",
        "\r\n",
        "            # forward + backward + optimize\r\n",
        "            loss = model.MSE(inputs)\r\n",
        "            with torch.no_grad():\r\n",
        "                compressed = model.compress(inputs) #of shape [batch_size, compress_dim]\r\n",
        "                FP_loss = model.FP(compressed, labels)\r\n",
        "            model.train(inputs,labels, iter = 10)\r\n",
        "            running_loss += loss\r\n",
        "            running_fp += FP_loss\r\n",
        "\r\n",
        "            # print statistics\r\n",
        "            running_loss += loss.item()\r\n",
        "            if i % 10 == 9:    # print every 2000 mini-batches\r\n",
        "                print(str(i) + 'complete!')\r\n",
        "                print(running_loss/10)\r\n",
        "                print(running_fp/10)\r\n",
        "                running_loss = 0.0\r\n",
        "                running_fp = 0.0\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOpJ1qCVuVfm"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\r\n",
        "neu = 40\r\n",
        "mean = 0\r\n",
        "scale = 1\r\n",
        "num_models = 10\r\n",
        "compress_dim = 6\r\n",
        "thres = 3\r\n",
        "\r\n",
        "def Output(x):\r\n",
        "    x = x.reshape([-1,10])\r\n",
        "    pred = torch.max(x, dim = 1)[1]\r\n",
        "    return pred\r\n",
        "\r\n",
        "\r\n",
        "def Train(model, loss, optimizer, inputs, labels):\r\n",
        "    model.train()\r\n",
        "    inputs = Variable(inputs, requires_grad=False)\r\n",
        "    labels = Variable(labels, requires_grad=False)\r\n",
        "    # reset gradient\r\n",
        "    optimizer.zero_grad()\r\n",
        "    # forward loop\r\n",
        "    logits = model.forward(inputs)\r\n",
        "    output = loss.forward(logits, labels)\r\n",
        "    # backward\r\n",
        "    output.backward()\r\n",
        "    optimizer.step()\r\n",
        "    return output.item()\r\n",
        "\r\n",
        "\r\n",
        "def get_error(model, inputs, labels, d):\r\n",
        "    model.eval()\r\n",
        "    inputs = Variable(inputs, requires_grad=False)\r\n",
        "    labels = Variable(labels, requires_grad=False)\r\n",
        "    logits = model.forward(inputs)\r\n",
        "    predicts = Output(logits)\r\n",
        "    a = predicts.shape[0]\r\n",
        "    k = 0\r\n",
        "    for i in range(a):\r\n",
        "        if predicts[i] == labels[i]:\r\n",
        "            k = k+1\r\n",
        "\r\n",
        "    return 1 - k / d\r\n",
        "\r\n",
        "\r\n",
        "def predict(model, inputs):\r\n",
        "    model.eval()\r\n",
        "    inputs = Variable(inputs, requires_grad=False)\r\n",
        "    logits = model.forward(inputs)\r\n",
        "    return logits\r\n",
        "\r\n",
        "        \r\n",
        "def process_t(inputs, labels, models):\r\n",
        "    Outputs = []\r\n",
        "    errs = []\r\n",
        "    with torch.no_grad():\r\n",
        "        for i in range(num_models):\r\n",
        "        \r\n",
        "            a = FCAEs[i].compress(inputs).reshape([-1,compress_dim]).clone().detach()\r\n",
        "        \r\n",
        "            Outputs.append(Variable(a,requires_grad=False))\r\n",
        "            \r\n",
        "\r\n",
        "\r\n",
        "    for i in range(num_models):\r\n",
        "        errs.append(get_error(models[i],Outputs[i], labels, bs))\r\n",
        "   \r\n",
        " \r\n",
        "    return errs\r\n",
        "\r\n",
        "def process(iter, inputs, labels, models):\r\n",
        "\r\n",
        "    Outputs = []\r\n",
        "    errs = []\r\n",
        "    with torch.no_grad():\r\n",
        "        for i in range(num_models):\r\n",
        "        \r\n",
        "            a = FCAEs[i].compress(inputs).reshape([-1,compress_dim]).clone().detach()\r\n",
        "        \r\n",
        "            Outputs.append(Variable(a,requires_grad=False))\r\n",
        "    \r\n",
        "    for i in range(num_models):\r\n",
        "        errs.append(get_error(models[i],Outputs[i], labels, bs))\r\n",
        "    \r\n",
        "    for j in range(iter):\r\n",
        "        #train(models[0], loss, optimizers[0], XTrain, YTrains[num])\r\n",
        "        #elif k == 1:\r\n",
        "        for i in range(num_models):\r\n",
        "            Train(models[i], loss, optimizers[i], Outputs[i], labels)\r\n",
        "            err = get_error(models[i],Outputs[i], labels, bs)\r\n",
        "            if err == 0:\r\n",
        "                break\r\n",
        "        \r\n",
        "    \r\n",
        "    return errs\r\n",
        "\r\n",
        "def get_loss(model, inputs, labels):\r\n",
        "    model.eval()\r\n",
        "    inputs = Variable(inputs, requires_grad=False)\r\n",
        "    labels = Variable(labels, requires_grad=False)\r\n",
        "    logits = model.forward(inputs)\r\n",
        "    #predicts = Output(logits)\r\n",
        "    l = loss(logits, labels)\r\n",
        "    return l\r\n",
        "\r\n",
        "def process_t_CE(inputs, labels):\r\n",
        "    Outputs = []\r\n",
        "    errs = []\r\n",
        "    with torch.no_grad():\r\n",
        "        for i in range(num_models):\r\n",
        "        \r\n",
        "            a = FCAEs[i].compress(inputs).reshape([-1,compress_dim]).clone().detach()\r\n",
        "        \r\n",
        "            Outputs.append(Variable(a,requires_grad=False))\r\n",
        "            \r\n",
        "\r\n",
        "\r\n",
        "    for i in range(num_models):\r\n",
        "      with torch.no_grad():\r\n",
        "        labels = labels.long()\r\n",
        "        errs.append(get_loss(models[i], Outputs[i], labels))\r\n",
        "   \r\n",
        " \r\n",
        "    return errs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwQC9uYHuXnq"
      },
      "source": [
        "FCAEs = []\r\n",
        "#betas = [0.001, 0.002, 0.003, 0.005, 0.007, 0.01, 0.02, 0.03, 0.05]\r\n",
        "for i in range(num_models):\r\n",
        "    FCAEs.append(FCAE([28,28,1], compress_dim = compress_dim, beta = 0.005, thres = thres))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez-6MJ9cuYPG"
      },
      "source": [
        "#FCAEs = []\r\n",
        "#betas = [0.001, 0.002, 0.003, 0.005, 0.007, 0.01, 0.02, 0.03, 0.05]\r\n",
        "#for i in range(num_models):\r\n",
        "    #FCAEs.append(FCAE([28,28,1], compress_dim = compress_dim, beta = 0.005, thres = thres))\r\n",
        "\r\n",
        "#del models\r\n",
        "MC_num = 1\r\n",
        "\r\n",
        "for t in range(MC_num):\r\n",
        "    i = 0\r\n",
        "    for FCAE in FCAEs:\r\n",
        "        i = i+1\r\n",
        "        print(i)\r\n",
        "        train(FCAE,1)\r\n",
        "    number_epoches = 10\r\n",
        "    iter = 10\r\n",
        "    plot_data = []\r\n",
        "    models = [] #3  models,baseline, FP, VAE\r\n",
        "    optimizers = []\r\n",
        "\r\n",
        "    for i in range(num_models):\r\n",
        "        #i = i + 1\r\n",
        "        models.append(torch.nn.Sequential())\r\n",
        "        models[i].add_module('FC1', torch.nn.Linear(compress_dim, neu))\r\n",
        "        models[i].add_module('relu1', torch.nn.ReLU())\r\n",
        "        models[i].add_module('FC2', torch.nn.Linear(neu, neu))\r\n",
        "        models[i].add_module('relu2', torch.nn.ReLU())\r\n",
        "        models[i].add_module('FC3', torch.nn.Linear(neu, 10))\r\n",
        "        #if i == 0:\r\n",
        "        with torch.no_grad():\r\n",
        "            torch.nn.init.normal_(models[i].FC1.weight, mean=mean, std=scale)\r\n",
        "            torch.nn.init.normal_(models[i].FC2.weight, mean=mean, std=scale)\r\n",
        "            torch.nn.init.normal_(models[i].FC3.weight, mean=mean, std=scale)\r\n",
        "        optimizers.append(optim.Adam(models[i].parameters(), lr=0.1))\r\n",
        "        models[i] = models[i].to(device)\r\n",
        "      \r\n",
        "    for epoch in range(number_epoches):  # loop over the dataset multiple times \r\n",
        "        #errs1, errs2, errs3 = [], [], []\r\n",
        "        for i, data in enumerate(mnist_trainloader, 0):\r\n",
        "            # get the inputs\r\n",
        "            inputs, labels = data\r\n",
        "            \r\n",
        "\r\n",
        "            # wrap them in Variable\r\n",
        "            inputs, labels = Variable(inputs.to(device), requires_grad=False), Variable(labels.to(device),requires_grad=False)\r\n",
        "            #inputs= Variable(inputs)\r\n",
        "\r\n",
        "            # forward + backward + optimize\r\n",
        "            errs = process(iter, inputs, labels, models)\r\n",
        "            #print(errs)\r\n",
        "            if i%10 == 9:\r\n",
        "                print(str(i) + ' complete ')\r\n",
        "        \r\n",
        "        number_epoch = 1\r\n",
        "        #iter = 50\r\n",
        "        for epoch in range(number_epoch):  # loop over the dataset multiple times \r\n",
        "            terrs = []\r\n",
        "            for i in range(num_models):\r\n",
        "                terrs.append([])\r\n",
        "            for i, data in enumerate(mnist_testloader, 0):\r\n",
        "                # get the inputs\r\n",
        "                inputs, labels = data\r\n",
        "\r\n",
        "\r\n",
        "                # wrap them in Variable\r\n",
        "                inputs, labels = Variable(inputs.to(device), requires_grad=False), Variable(labels.to(device),requires_grad=False)\r\n",
        "                #inputs= Variable(inputs)\r\n",
        "\r\n",
        "                # forward + backward + optimize\r\n",
        "                terr = process_t(inputs, labels, models)\r\n",
        "                for j in range(num_models):\r\n",
        "                    terrs[j].append(terr[j])\r\n",
        "                if i%10 == 9:\r\n",
        "                    print(str(i) + ' complete ')\r\n",
        "                    #print(errs[0])\r\n",
        "                    \r\n",
        "        a = []\r\n",
        "        for i in range(num_models):\r\n",
        "            a.append(sum(terrs[i])/5)\r\n",
        "        print('the mean error is')\r\n",
        "        print(a)\r\n",
        "        print(sum(a)/10)\r\n",
        "        plot_data.append(sum(a)/10)\r\n",
        "\r\n",
        "    del models\r\n",
        "\r\n",
        "    plot_datas.append(plot_data)\r\n",
        "    torch.save(plot_datas, 'err_fcae_cd4.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}